# Описание

### Общие мысли
В общем случае, задача распознавания блюд очень сложна, потому что модель работает только с поверхностью тарелки 
и вынуждена максимально полагаться на стиль оформления блюда и цвет продукта, который может меняться в зависимости от добавления особых ингредиентов. Некоторые блюда (например, мясо с костями) не сильно отличаются до и после еды.

### Разбиение видео на кадры
Для генерации датасета нужно поместить видеофайлы в папку **data** и запустить
```
bash split_into_frames.sh
```
Для его выполнения требуется наличие в системе пакета **ffmpeg**. В результате, получим 4 папки "video..." внутри **data**.


### Упрощение датасета
Изображения практически не меняются во времени, а нужные нам объекты большие по размеру в пикселях, поэтому можно отобрать каждый 5 кадр и уменьшить каждое измерение в 4 раза. После исполнения
```
python reduce_dataset.py
```
получим 4 папки "split_video..." внутри **data**.


### Получение разметки
Для получения разметки воспользуемся SAM2, выполнив
```
https://github.com/facebookresearch/sam2
cd sam2
SAM2_BUILD_CUDA=0 pip install -e ".[notebooks]"
cp ../annotate_dataset.py ./
python annotate_dataset.py
```
Модель SAM2 генерирует трек основного объекта в видео, представленном набором изображений, внутри заданного бокса. Наша сцена семантически простая, поэтому достаточно модели "s". В результате, получаем файл аннотаций **all_annotations.json** внутри **data**. Данный шаг можно пропустить: **all_annotations.json** доступен в репозитории, его только нужно поместить внутрь **data**.


### Замечание
Производить аугментацию на стадии подготовки датасета не имеет никакого смысла, особенно, в условиях ограниченности датасета. Но и в нормальных условиях это остается в силе. Обучающий процесс ultralytics позволяет определенный уровень кастомизации. В частности, возможно изменять набор аугментаций в рамках обучения модели. Если необходимо бОльшая кастомизация, можно создать класс CustomDataset и использовать код
```
# Initialize YOLO model
model = YOLO('yolov8n.yaml')

# Replace the default dataset with your custom dataset
model.dataset = CustomDataset()

# Train the model
model.train()
```

### Создание датасета 
В нашем случае задача является тривиальной ввиду максимальной ограниченности датасета: есть видео "до" и "после", и внутри групп, по сути, одно и то же. Это делает разбиение датасета на выборки сложнореализуемой, так что пойдем стандартным путем - разнесением видео по выборкам: на **2_1.MOV** будем обучаться, на остальных - валидироваться. Ввиду отсутствия какого-либо разнообразия в датасете обобщающую способность измерить нереально, так что будем формировать .


### Замечание
Для процесса обучения важно не только наличие примеров всех объектов, но и негативные примеры, что не является объектом, поэтому в обучающую выборку добавляется один кадр из видео "3_2.MOV"


### Замечание
Учитывая, что нас интересует присутствие блюда в сцене, mAP не является существенной характеристикой - важнее полнота и точность.



### Замечание
Учитывая стационарность сцен и отсутствие пересечений объектов, возможная альтернатива - использование сегментации для получения отдельных объектов на столе с последующей классификацией небольших изображений.
